token {
    ANYCHAR;
    NEWLINE;
    TOKEN;
    PUNCT;
    WS;
}


define {
    // CHARACTERS CLASSES:
    SYMBOL              [: intersection( {BASE_CLASS}, \G{S} ) :]
    // punctuations (all):
    PUNCT               [: intersection( {BASE_CLASS}, \G{P} ) :]
    // joinable punctuations:
    SYMS                "&#x"("02c5"|"02ef"|"1f4b6"|"00a"[9e]|"00b"[239]|"02e"[123]|"02b"[01]|"2"[0-9ab][0-9a-f][0-9a-f])";"
    PUNCT_JOINABLE_CHAR [.?!~@#$%^*+=<>_¢¤§·×÷°,:;\-]
    PUNCT_JOINABLE      ({PUNCT_JOINABLE_CHAR}|"&ndash;"|"&mdash;"|{SYMS})

    // RULE FRAGMENTS
    // word token with dot:
    WORD                "."?({WORDCHAR2}+"."?)+
    WORD_IN_PAR         "("{WORD}")"
    // U R L ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    PROTOKOLL           [a-zA-Z][a-zA-Z0-9+.\-]+"://"
    USER                [a-zA-Z0-9][a-zA-Z0-9.]*
    PASSWD              [!-~]+
    AUTH                {USER}(":"{PASSWD})?"@"
    // IP_FRAG: numbers between 0-255
    IP_FRAG             ([1-9]?[0-9])|("1"[0-9]{2})|("2"[0-4][0-9])|("25"[0-5])
    // IP: 4 IP_FRAG separated with dots, e.g. 142.42.1.1
    IP                  ({IP_FRAG}"."){3}{IP_FRAG}
    // DOMAIN_FRAG: dns label, must not begin and end with a hyphen
    // TODO: internationalized domain name
    DOMAIN_FRAG         [a-zA-Z0-9]([a-zA-Z0-9\-]*[a-zA-Z0-9])?
    DOMAIN              ({DOMAIN_FRAG}".")*{DOMAIN_FRAG}
    // TODO: IPv6
    HOST                {IP}|{DOMAIN}
    PORT                ":"[0-9]{2,5}
    URL_PATH_FRAG       [a-zA-Z0-9_\-\/()]+
    URL_PATH            "/"(({URL_PATH_FRAG}".")*{URL_PATH_FRAG})?
    QUERY               "?"[a-zA-Z0-9_\-./;&=+%:~]*[a-zA-Z0-9_\-/;&=+%:~]
    FRAGMENT            "#"[a-zA-Z0-9_\-./;&=+%:~]*[a-zA-Z0-9_\-/;&=+%:~]
    URL                 {PROTOKOLL}?{AUTH}?{HOST}{PORT}?{URL_PATH}?{QUERY}?{FRAGMENT}?

    // P A T H ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    // windows
    WIN_PATH_INIT   ([a-zA-Z]":")|("\\")
    WIN_PATH_FRAG   "\\"[a-zA-Z0-9.$]+
    WIN_PATH_SHORT  [a-zA-Z]":""\\"?
    WIN_PATH        ({WIN_PATH_SHORT})|({WIN_PATH_INIT}{WIN_PATH_FRAG}*)
    // unix
    UNIX_PATH_INIT  "."{0,2}
    UNIX_PATH_FRAG  "/"([a-zA-z0-9]|"\\ ")*
    UNIX_PATH       {UNIX_PATH_INIT}{UNIX_PATH_FRAG}+
    // path
    PATH            {UNIX_PATH}|{WIN_PATH}
}



// M O D E S
start = PROGRAM;

// basic processing
mode PROGRAM : COMMON {

    // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    // beginning / end of sentence
    {SNT_OPEN_QX}|{SNT_CLOSE_QX}   => TOKEN_ANYCHAR(Lexeme);

    // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    // whitespaces (out sentence)
    {TAGGED_WS_SEQ} => TOKEN_WS(Lexeme);

    // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    // whitespaces (in sentence)
    {WSPACE}+ {
        std::wstring LEX(Lexeme);
        LEX = self.WS_OPEN_CPP + LEX + self.WS_CLOSE_CPP;
        self_send1(TOKEN_WS, LEX.c_str());
    }

    // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    // basic tokenizer rules:
    // - tokens can contain wordchars and dots, but dot can not follow another
    //   dot
    // - dot at the end of the word belongs to the sentence, if it is followed
    //   by a snt close tag
    // - words with parenthesis: (paren)thesis or paren(thesis), or
    //   par(en)thesis, but not (parenthesis)
    // verision for words with "-e"
    ((({WORD}?{WORD_IN_PAR})?{WORD})|({WORD}?{WORD_IN_PAR}))"-e"("."{SNT_CLOSE_QX})? {
        std::wstring LEX(Lexeme);
        self.word_end_corrig(LEX);
        self_send1(TOKEN_TOKEN, LEX.c_str());
    }
    /* // verision for words with "-e" */
    /* ((({WORD_IN_PAR})?{WORD})|({WORD}?{WORD_IN_PAR}{WORD}?))"-e" { */
    /*     std::wstring LEX(Lexeme); */
    /*     self.word_end_corrig(LEX); */
    /*     self_send1(TOKEN_TOKEN, LEX.c_str()); */
    /* } */
    // version for other cases:
    ((({WORD_IN_PAR})?{WORD})|({WORD}{WORD_IN_PAR}{WORD}?))("."{SNT_CLOSE_QX})? {
        std::wstring LEX(Lexeme);
        self.snt_end_corrig(LEX);
        self_send1(TOKEN_TOKEN, LEX.c_str());
    }

    // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    // punctuations
    ({PUNCT_JOINABLE}+)|{PUNCT}|{SYMBOL} {
        std::wstring LEX(Lexeme);
        LEX = self.PUNCT_OPEN_CPP + LEX + self.PUNCT_CLOSE_CPP;
        self_send1(TOKEN_PUNCT, LEX.c_str());
    }

    // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    // url
    {URL}("-"?{WORD})?("."{SNT_CLOSE_QX})? {
        std::wstring LEX(Lexeme);
        self.snt_end_corrig(LEX);
        self_send1(TOKEN_TOKEN, LEX.c_str());
    }

    // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    // email
    // it seems, it's ready :)

    // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    // windows network services (?)
    [a-zA-Z]+"$"{WORD}?("."{SNT_CLOSE_QX})? {
        std::wstring LEX(Lexeme);
        self.snt_end_corrig(LEX);
        self_send1(TOKEN_TOKEN, LEX.c_str());
    }
    // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    // path
    {PATH}("-"?{WORD})?("."{SNT_CLOSE_QX})? {
        std::wstring LEX(Lexeme);
        self.snt_end_corrig(LEX);
        self_send1(TOKEN_TOKEN, LEX.c_str());
    }
}


// kozos dolgok
mode COMMON : <inheritable: only> {
    /* {NEWLINE}       => TOKEN_NEWLINE(Lexeme); */
    on_failure      => TOKEN_TERMINATION;
    /* on_failure      { */
    /*     std::wcout << L"HIBA: >>" << Lexeme << L"<<\n"; */
    /*     self_send1(TOKEN_ANYCHAR, Lexeme); */
    /* } */
    <<EOF>>         => TOKEN_TERMINATION;
}

